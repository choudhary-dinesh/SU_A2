# -*- coding: utf-8 -*-
"""kathbath_hindi_speaker_verification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FcPooYfhuwL9_604gLbvwOzaQ0vxU_IW

#### KB Hindi Dataset
"""

!unzip /content/drive/MyDrive/kb_hindi.zip

import glob
m4a_list = glob.glob("/content/kb_hindi/*.m4a")

#male speaker 58
#female speaker 63

"""#### convert m4a to wav format using ffmpeg"""

!sudo apt install ffmpeg

for fil in glob.glob("/content/kb_hindi/*.m4a")[:]:
  out_fil = '/content/drive/MyDrive/kb_hindi_wav/' + fil.split('/')[-1][:-4] + '.wav'
  !ffmpeg -hide_banner -loglevel error -y -i {fil} -ar 16000 {out_fil}

import glob
len(glob.glob("/content/drive/MyDrive/kb_hindi_wav/*.wav"))

kb_hindi_path  = "/content/drive/MyDrive/kb_hindi_wav/"

"""#### install fairseq"""

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/pytorch/fairseq

# Change current working directory
!pwd
# %cd "/content/fairseq"
!pip install --editable ./

!pip install fairseq

"""#### clone UniSpeech"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content

!git clone https://github.com/microsoft/UniSpeech



"""#### install requirements"""

# !pip install s3prl==0.3.1
!pip install fire==0.4.0
!pip install sentencepiece==0.1.96

!sudo apt-get install sox

!pip install s3prl@git+https://github.com/s3prl/s3prl.git@7ab62aaf2606d83da6c71ee74e7d16e0979edbc3#egg=s3prl

!pip install s3prl

!pip install omegaconf==2.0.6

"""#### Speaker verification using pretrianned Wavlm_Large model (few sample)"""

!pwd

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/UniSpeech/downstreams/speaker_verification

# checkpoint_path = 'config/unispeech_sat.th'
# checkpoint_path = "/content/drive/MyDrive/hubert_large_finetune.pth"
checkpoint_path = "/content/drive/MyDrive/wavlm_large_finetune.pth"

import glob
hindi_wav_list  = glob.glob('/content/drive/MyDrive/kb_hindi_wav/*.wav')
hindi_wav_list[:3]

"""##### 2 same speakers"""

!python verification.py --model_name wavlm_large \
 --wav1 /content/drive/MyDrive/kb_hindi_wav/844424930656675-929-m.wav \
 --wav2 /content/drive/MyDrive/kb_hindi_wav/844424930656675-929-m.wav \
 --checkpoint /content/drive/MyDrive/Classroom/wavlm_large_finetune.pth

"""##### 2 different speaker"""

!python verification.py --model_name wavlm_large \
 --wav1 /content/drive/MyDrive/kb_hindi_wav/844424930656675-929-m.wav \
 --wav2 /content/drive/MyDrive/kb_hindi_wav/844424930648278-384-f.wav \
 --checkpoint /content/drive/MyDrive/Classroom/wavlm_large_finetune.pth



"""#### Speaker verification using Hubert_Large model (few sampels)"""

# %cd /content/UniSpeech/downstreams/speaker_verification

# checkpoint_path = 'config/unispeech_sat.th'
checkpoint_path = "/content/drive/MyDrive/Classroom/hubert_large_finetune.pth"
# checkpoint_path = "/content/drive/MyDrive/Classroom/wavlm_large_finetune.pth"

"""##### 2 same speaker"""

!python verification.py --model_name hubert_large \
 --wav1 /content/drive/MyDrive/kb_hindi_wav/844424930656675-929-m.wav \
 --wav2 /content/drive/MyDrive/kb_hindi_wav/844424930656675-929-m.wav  \
 --checkpoint /content/drive/MyDrive/Classroom/hubert_large_finetune.pth

"""##### 2 different speaker"""

!python verification.py --model_name hubert_large \
 --wav1 /content/drive/MyDrive/kb_hindi_wav/844424930656675-929-m.wav \
 --wav2 /content/drive/MyDrive/kb_hindi_wav/844424930648278-384-f.wav  \
 --checkpoint /content/drive/MyDrive/Classroom/hubert_large_finetune.pth



"""#### prediction on subsample of kb_hindi

"""

from verification import verification
# added return sim[0].item() at end of verificaion function in verification.py to return score

similarity_score = verification(model_name = 'hubert_large',
                                wav1 = '/content/drive/MyDrive/kb_hindi_wav/844424930656675-929-m.wav',
                                wav2 = '/content/drive/MyDrive/kb_hindi_wav/844424930648278-384-f.wav' ,
                                checkpoint = '/content/drive/MyDrive/Classroom/hubert_large_finetune.pth' )

similarity_score

import pandas as pd
import itertools
import random
from tqdm import tqdm
tqdm.pandas()

df = pd.DataFrame(hindi_wav_list, columns = ['wav_file'])
df['speaker_id'] = df.wav_file.apply(lambda x : '-'.join(x.split('/')[-1].split('.')[0].split('-')[1:]))
df.head(2)

same_speaker_pairs = []
different_speaker_pairs = []

grouped = df.groupby('speaker_id')
for speaker_id, group in grouped:
    pairs = list(itertools.combinations(group['wav_file'], 2))
    same_speaker_pairs.extend(pairs)

    other_speaker_groups = [g['wav_file'] for s_id, g in grouped if s_id != speaker_id]
    for other_group in other_speaker_groups:
        different_speaker_pairs.extend(list(itertools.product(group['wav_file'], other_group)))

random.shuffle(same_speaker_pairs)
random.shuffle(different_speaker_pairs)

#taking 50 pair for same spekar and 50 for differnt spkear
pair1 = same_speaker_pairs[:50]
pair0 = different_speaker_pairs[:50]
df1 = pd.DataFrame(pair0)
df1['label'] = 0
df2 = pd.DataFrame(pair1)
df2['label'] = 1
data_df= pd.concat([df1, df2])
data_df.columns = ['wav1', 'wav2', 'label']
data_df.shape, data_df.columns

data_df.head(2).values

data_df.tail(2).values

hubert_df = data_df.copy(deep = True)

hubert_df['hubert_large_pred'] = hubert_df.progress_apply(lambda x:verification(model_name = 'hubert_large',
                                                          wav1 =x['wav1'],wav2 = x['wav2'],
                                          checkpoint=  '/content/drive/MyDrive/Classroom/hubert_large_finetune.pth'),
                                                          axis =1)

hubert_df.to_csv("/content/drive/MyDrive/hubert_hindi_result.csv")

wavlm_df =  data_df.copy(deep = True)

wavlm_df['wavlm_large_pred'] = wavlm_df.progress_apply(lambda x:verification(model_name = 'wavlm_large',
                                                          wav1 =x['wav1'],wav2 = x['wav2'],
                                          checkpoint= '/content/drive/MyDrive/Classroom/wavlm_large_finetune.pth'),
                                                       axis =1)

wavlm_df.to_csv("/content/drive/MyDrive/wavlm_hindi_result.csv")

"""#### Evaluation  (EER)"""

hubert_df.head(2)

wavlm_df.head(2)

wavlm_pred_label = [ 0 if each < 0.5 else 1 for each in wavlm_df.wavlm_large_pred.tolist()]
hubert_pred_label = [ 0 if each < 0.5 else 1 for each in hubert_df.hubert_large_pred.tolist()]

wavlm_true_score = wavlm_df.label.tolist()
hubert_true_score  = hubert_df.label.tolist()

from sklearn.metrics import accuracy_score, precision_score, recall_score

def calculate_metrics(true_labels, predicted_labels):
    accuracy = accuracy_score(true_labels, predicted_labels)
    precision = precision_score(true_labels, predicted_labels)
    recall = recall_score(true_labels, predicted_labels)
    return accuracy, precision, recall

accuracy, precision, recall = calculate_metrics(wavlm_true_score, wavlm_pred_label)
print("Wavelm Large Accuracy on KB Hindi:", accuracy)
print("Wavelm Large Precision KB Hindi:", precision)
print("Wavelm Large Recall KB Hindi:", recall)

accuracy, precision, recall = calculate_metrics(hubert_true_score, hubert_pred_label)
print("Hubert Large Accuracy on KB Hindi:", accuracy)
print("Hubert Large Precision on KB Hindi:", precision)
print("Hubert Large Recall on KB Hindi :", recall)

import numpy as np
from sklearn.metrics import confusion_matrix

def calculate_far_frr(true_labels, similarity_scores, thresholds):
    eer = float('inf')
    eer_threshold = None
    far_frr = []
    FAR = 0
    FRR = 0
    for threshold in thresholds:
        # Calculate predictions based on the given threshold
        predictions = (similarity_scores >= threshold).astype(int)

        # Generate confusion matrix
        cm = confusion_matrix(true_labels, predictions)

        # Extract values from confusion matrix
        tn, fp, fn, tp = cm.ravel()

        # Calculate FAR and FRR
        far = fp / (fp + tn)
        frr = fn / (fn + tp)

        far_frr.append((threshold, far * 100, frr * 100))

        # Check if EER threshold needs to be updated
        if abs(far - frr) < eer:
            eer = abs(far - frr)
            eer_threshold = threshold
            FAR = far
            FRR = frr
    return far_frr, eer_threshold, FAR, FRR

#true labels and similarity scores
true_labels = hubert_true_score
similarity_scores = hubert_df.hubert_large_pred.tolist()

# Define a range of thresholds
thresholds = np.linspace(-1, 1, num=100)

# Calculate FAR, FRR, and EER
far_frr, eer_threshold, FAR, FRR = calculate_far_frr(true_labels, similarity_scores, thresholds)

print("Threshold\tFAR\t\tFRR")
for threshold, far, frr in far_frr:
  print("{:.4f}\t\t{:.2f}%\t\t{:.2f}%".format(threshold, far, frr))

print("\n Hubert False Rejection Rate (FAR) on KB Hindi:", FAR)
print("\n Hubert False Accaptance Rate (FRR)on KB Hindi:", FRR)
print("\nHubert Equal Error Rate (EER) Threshold on KB Hindi:", eer_threshold)

# true labels and similarity scores
true_labels = wavlm_true_score
similarity_scores = wavlm_df.wavlm_large_pred.tolist()

# Define a range of thresholds
thresholds = np.linspace(-1, 1, num=100)

# Calculate FAR, FRR, and EER
far_frr, eer_threshold, FAR, FRR = calculate_far_frr(true_labels, similarity_scores, thresholds)

print("Threshold\tFAR\t\tFRR")
for threshold, far, frr in far_frr:
  print("{:.4f}\t\t{:.2f}%\t\t{:.2f}%".format(threshold, far, frr))

print("\n Wavelm False Rejection Rate (FAR):", FAR)
print("\n Wavelm False Accaptance Rate (FRR):", FRR)
print("\n Wavelm Equal Error Rate (EER) Threshold:", eer_threshold)

