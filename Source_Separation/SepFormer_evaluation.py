# -*- coding: utf-8 -*-
"""SU_2_SepFormer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11lW6easWiVaujGWazyQ-hiNtJz93Vx2k

#### Libri2MixDatasat

##### imports
"""

import glob
import random
import os
from tqdm import tqdm
import pandas as pd

"""##### load & unzip libri2mix"""

# ! cp /content/libri2mix_test_clean_8k_max_mix_clean.zip /content/drive/MyDrive/Classroom/

!unzip //content/drive/MyDrive/Classroom/libri2mix_test_clean_8k_max_mix_clean.zip

!cp -r /content/content/LibriMix/storage_dir/Libri2Mix/wav8k/max/test/mix_clean/ /content/

datasat_path = '/content/mix_clean/'
file_list = glob.glob(datasat_path + '/*.wav')
len(file_list), file_list[0]

test_size = 0.30
test_files_count = int(len(file_list) *test_size)
random.shuffle(file_list)

test_data_files = file_list[0:test_files_count]
train_data_files = file_list[test_files_count:]
print("total no of files in test set : ", len(test_data_files))
print("total no of files in train set : ", len(train_data_files))

"""#### LibriSpeech test-clean dataset

This is to download original librispeech dataset of test-clean set, as we already have uplaoded mixed dataset (libri2mix) above, this original dataset is required for evaluation as well
"""

import torchaudio
from torchaudio.datasets import LIBRISPEECH

librispeech_test_clean = LIBRISPEECH(root = '/content/',
                                    url = 'test-clean',
                                    # folder_in_archive: str = 'LibriSpeech',
                                    download= True)

"""#### SepFormer Model Evaluation

##### Install
"""

!pip install speechbrain

!pip install torchmetrics

"""##### imports"""

device  = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
device

from speechbrain.inference.separation import SepformerSeparation as separator
import torch
from torch import tensor
from torchmetrics.audio import ScaleInvariantSignalNoiseRatio
from torchmetrics.audio import ScaleInvariantSignalDistortionRatio
# create object for si-snr & si-sdr which will be used for si-snri & si-sdri calculation
si_snr = ScaleInvariantSignalNoiseRatio().to(device)
si_sdr = ScaleInvariantSignalDistortionRatio().to(device)

"""##### load pretrained model"""

model = separator.from_hparams(source="speechbrain/sepformer-whamr",
                               savedir='pretrained_models/sepformer-whamr',
                          run_opts={"device":"cuda"})

"""##### predict single sample"""

# for custom file, change path
sources_pred = model.separate_file(path='/content/mix_clean/1221-135766-0012_6930-76324-0003.wav')
# torchaudio.save("source1hat.wav", sources_pred[:, :, 0].detach().cpu(), 8000)
# torchaudio.save("source2hat.wav", sources_pred[:, :, 1].detach().cpu(), 8000)

mixture, sr = torchaudio.load('/content/mix_clean/1221-135766-0012_6930-76324-0003.wav')

sources_pred.shape, mixture.shape

"""##### prediction and evaluation on all test set (900 files)"""

### function for SI-SNR improvement metircx using torchmetrics.audio.ScaleInvariantSignalNoiseRatio
def SI_SNRi(src_ref, src_est, mix):
  sisnr1 = si_snr(src_ref[:,:,0], src_est[:,:,0])
  sisnr2 = si_snr(src_ref[:,:,1], src_est[:,:,1])

  sisnr1b = si_snr(src_ref[:,:,0], mix)
  sisnr2b = si_snr(src_ref[:,:,1], mix)

  avg_SISNRi = ((sisnr1 - sisnr1b) + (sisnr2 - sisnr2b)) / 2
  return avg_SISNRi

# function for SI-SDR improvement metircx using torchmetrics.audio.ScaleInvariantSignalDistortionRatio
def SI_SDRi(src_ref, src_est, mix):
  sisdr1 = si_snr(src_ref[:,:,0], src_est[:,:,0])
  sisdr2 = si_snr(src_ref[:,:,1], src_est[:,:,1])

  sisdr1b = si_snr(src_ref[:,:,0], mix)
  sisdr2b = si_snr(src_ref[:,:,1], mix)

  avg_SISDRi = ((sisdr1 - sisdr1b) + (sisdr2 - sisdr2b)) / 2

  return avg_SISDRi

len(test_data_files), test_data_files[0]

evaluation_results = []
for libri2mix_path in tqdm(test_data_files[:]):
  #create source 1 & source 2 flac file path
  s1_path, s2_path = libri2mix_path[:-4].split('/')[-1].split('_')
  s1_path =  '/content/LibriSpeech/test-clean/' + '/'.join(s1_path.split('-')[:2]) +'/'+ s1_path + '.flac'
  s2_path = '/content/LibriSpeech/test-clean/' + '/'.join(s2_path.split('-')[:2]) +'/'+ s2_path + '.flac'

  #read s1 & s2 flac files andresample them into 8000 sample rate as mixing is done using 8k sample rate
  s1, sample_rate1 = torchaudio.load(s1_path)
  resampler = torchaudio.transforms.Resample(sample_rate1, 8000)
  s1_8k = resampler(s1)
  s2, sample_rate2 = torchaudio.load(s2_path)
  resampler = torchaudio.transforms.Resample(sample_rate2, 8000)
  s2_8k = resampler(s2)

  #zero pad shorter source signal to match shape of both source signal
  if s1_8k.shape[-1]>s2_8k.shape[-1]:
    s2_8k = torch.nn.functional.pad(s2_8k, (0, s1_8k.shape[-1] -s2_8k.shape[-1]))
  else:
    s1_8k = torch.nn.functional.pad(s1_8k, (0, s2_8k.shape[-1] -s1_8k.shape[-1] ))

  #stack source 1 & 2 into single tensor to get source_true signal
  source_true = torch.stack((s1_8k, s2_8k), dim=2)

  #load libri2mix_path (mixed wav file)
  mixture, _ = torchaudio.load(libri2mix_path)

  #predict over mix signal using sepformer model to get source seprated signal
  sources_pred = model.separate_file(libri2mix_path)
  s1_pred = sources_pred[:, :, 0].detach().to(device)
  s2_pred = sources_pred[:, :, 1].detach().to(device)

  ## calculate si-snr & si-sdr
  si_snr1 = si_snr(s1_pred, s1_8k.to(device))
  si_snr2 = si_snr(s2_pred, s2_8k.to(device))

  si_sdr1 = si_sdr(s1_pred, s1_8k.to(device))
  si_sdr2 = si_sdr(s2_pred, s2_8k.to(device))

  #caculate si-snri & si-sdri
  si_snri = SI_SNRi(source_true.to(device), sources_pred.to(device), mixture.to(device))
  si_sdri = SI_SDRi(source_true.to(device), sources_pred.to(device), mixture.to(device))

  #append metirced to result list
  evaluation_results.append([libri2mix_path, float(si_snr1), float(si_snr2), float(si_sdr1),
                             float(si_sdr2), float(si_snri), float(si_sdri)])

evaluation_results[:2]

df = pd.DataFrame(evaluation_results, columns = ['file', 'si_snr1', 'si_snr2', 'si_sdr1', 'si_sdr2',
                                                 'si_snri', 'si_sdri'])
float_columns = df.select_dtypes(include=['float']).columns
# Apply abs function to float value columns
df[float_columns] = df[float_columns].applymap(abs)

df.head()

df[float_columns].mean()

